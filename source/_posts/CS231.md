---
title: CS231
date: 2018-03-09 07:47:11
tags: [ML]
categories: [机器学习和数据处理python备忘]
---
##### 4.1
- backprop反向传播 链式法则的递归调用
![backprop.jpg](https://iota-1254040271.cos.ap-shanghai.myqcloud.com/image/backprop.jpg)
反向传播可以得到损失函数L因为
$\frac{\partial L}{\partial x} = \frac{\partial L}{\partial z}\frac{\partial z}{\partial x}$
利用上游传回的梯度 反向计算每个节点的本地梯度 最后一个节点的梯度总是1？
![backpropexample.jpg](https://iota-1254040271.cos.ap-shanghai.myqcloud.com/image/backpropexample.jpg)
- 加法门是gradient distributor加法节点之前的本地梯度是1,分支与上游又相同梯度
- max门通过后本地梯度分别是0，1 （max只有一个值可以影响上游）
- mul乘法门 对上游值缩放
![sigmoid.jpg](https://iota-1254040271.cos.ap-shanghai.myqcloud.com/image/sigmoid.jpg)

  